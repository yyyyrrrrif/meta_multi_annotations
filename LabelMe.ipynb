{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-*- coding : utf-8 -*-\n",
    "# coding: utf-8\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "\n",
    "### dataset\n",
    "DATA_PATH = '../Downloads/LabelMe/prepared/'\n",
    "N_CLASSES = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelMe_dataset(data.Dataset):\n",
    "    def __init__(self, data_type, data_path):\n",
    "#     def __init__(self, data_type='train', data_path):\n",
    "        self.data_type = data_type\n",
    "        self.data_path = data_path\n",
    "        # load train data\n",
    "        # images processed by VGG16\n",
    "        self.data_vgg16 = np.load(self.data_path + \"data_%s_vgg16.npy\" % self.data_type)\n",
    "        # ground truth labels\n",
    "        self.labels = np.load(self.data_path + \"labels_%s.npy\" % self.data_type)\n",
    "        \n",
    "        # data from Amazon Mechanical Turk       \n",
    "        if self.data_type == 'train':\n",
    "            self.answers = np.load(self.data_path + \"answers.npy\")\n",
    "#             N_ANNOT = answers.shape[1]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.labels.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        ftrs = self.data_vgg16[idx, :, :, :]\n",
    "        true_label = self.labels[idx]\n",
    "\n",
    "        if self.data_type == 'train':\n",
    "            multi_label = self.answers[idx, :]\n",
    "            return ftrs, true_label, multi_label\n",
    "        else:\n",
    "            return ftrs, true_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = LabelMe_dataset('train', DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = LabelMe_dataset('test', DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1188"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "### model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class net(nn.Module):\n",
    "    def __init__(self, n_class):\n",
    "        super(net, self).__init__()\n",
    "        self.fc1 = nn.Linear(4*4*512, 128)\n",
    "        self.fc2 = nn.Linear(128, n_class)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = x.view(-1)\n",
    "        out = self.fc1(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc2(out)\n",
    "        out = F.softmax(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = net(n_class=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.from_numpy(train_data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:19: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.1228, 0.1601, 0.1384, 0.1108, 0.1481, 0.0779, 0.1211, 0.1208],\n",
       "       grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = train_data[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = torch.from_numpy(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  4,  4, -1,\n",
       "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "        -1, -1, -1, -1, -1,  4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "        -1, -1, -1, -1, -1])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "        -1, -1, -1, -1, -1])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mm = torch.tensor([-1]*len(y_true))\n",
    "mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True, False, False,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True, False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true.eq(mm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ True, False])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([True, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.where(torch.tensor([True, False]), torch.tensor([1,1]), torch.tensor([2,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        >>> # input is of size N x C = 3 x 5\n",
    "        >>> input = torch.randn(3, 5, requires_grad=True)\n",
    "        >>> # each element in target has to have 0 <= value < C\n",
    "        >>> target = torch.tensor([1, 0, 4])\n",
    "        >>> output = F.nll_loss(F.log_softmax(input), target)\n",
    "        >>> output.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.8253,  1.0232, -1.3994,  0.3407,  0.7747],\n",
       "        [-0.9056,  0.1924, -1.6498, -0.4747,  0.6425],\n",
       "        [-0.3987, -1.4826, -0.6371, -1.1593,  1.3939]], requires_grad=True)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 4])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = torch.tensor([1, 0, 4])\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(1.4192, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = F.nll_loss(F.log_softmax(input), target)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def one_hot(target, n_classes):\n",
    "    targets = np.array([target]).reshape(-1)\n",
    "    one_hot_targets = np.eye(n_classes)[targets]\n",
    "    return one_hot_targets\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-13774613edc6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mone_hot_y_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mone_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mone_hot_y_true\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-75-21ebee1db12c>\u001b[0m in \u001b[0;36mone_hot\u001b[0;34m(target, n_classes)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mone_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mone_hot_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mone_hot_targets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "one_hot_y_true = one_hot(y_true,8)\n",
    "one_hot_y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(target, n_classes):\n",
    "    targets = np.array([target]).reshape(-1)\n",
    "    one_hot_targets = np.eye(n_classes)[targets]\n",
    "    return one_hot_targets\n",
    "\n",
    "def multi_annot_one_hot(answers, N_CLASSES):\n",
    "    row = []\n",
    "    for i in range(len(answers)):\n",
    "        if answers[i] == -1:\n",
    "            row.append(-1 * np.ones(N_CLASSES))\n",
    "        else:\n",
    "            row.append(one_hot(answers[i], N_CLASSES)[0,:])\n",
    "    row = np.array(row)\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  4,  4, -1,\n",
       "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "        -1, -1, -1, -1, -1,  4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "        -1, -1, -1, -1, -1])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "       [-1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "       [-1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "       [-1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "       [-1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "       [-1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "       [-1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "       [-1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "       [-1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "       [-1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "       [-1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "       [-1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "       [-1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "       [-1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "       [-1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.],\n",
       "       [-1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "       [-1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "       [-1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "       [-1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "       [-1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "       [-1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "       [-1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "       [-1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "       [-1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "       [-1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "       [-1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "       [-1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "       [-1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "       [-1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "       [-1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "       [-1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "       [-1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "       [-1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "       [-1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "       [-1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "       [-1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "       [-1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "       [-1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "       [-1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.],\n",
       "       [-1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "       [-1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "       [-1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "       [-1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "       [-1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "       [-1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "       [-1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "       [-1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "       [-1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "       [-1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "       [-1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "       [-1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "       [-1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "       [-1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "       [-1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "       [-1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "       [-1., -1., -1., -1., -1., -1., -1., -1.]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_annot_one_hot(y_true, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
